# NLP Resources

Here are some links to resources about the core concepts of Natural Language Process
that will help you get started with Haystack.

## What is NLP?

|||||
|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|-----------------|----------------------------------------------------------------------------------------------------------------|
| [Natural Language Processing (NLP)](https://www.ibm.com/cloud/learn/natural-language-processing#toc-nlp-tasks-K4EAXccS)                                         | Blog           | IBM             | High level introduction to the tasks, tools and use cases of NLP.                                              |   |
| [Stanford NLP Course](https://www.youtube.com/watch?v=oWsMIW-5xUc&list=PLLssT5z_DsK8HbD2sPcUIDfQ7zmBarMYv&index=1)                                              | Youtube        | Dan Jurafsky    | Comprehensive set of videos covering many different topics. Can get very technical and in depth quite quickly. |   |
| [Text Classification with NLP: Tf-Idf vs Word2Vec vs BERT](https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794) | Blog with Code | Mauro Di Pietro | A hands of and in depth dive into text classification using three different methods.                           |   |

## Search and Question Answering

|||||
|------------------------------------------------------------------------------------------------------------------------|------|------------------------|-------------------------------------------------------------------------------------------------------------------------------------|
| [Question Answering at Scale With Haystack](https://www.deepset.ai/blog/haystack-question-answering-at-scale)          | Blog | Branden Chan (deepset) | High level description of the Retriever-Reader pipeline that gives some intuition about how they work and how they can be deployed. |
| [Haystack: The State of Search in 2021](https://www.deepset.ai/blog/haystack-the-state-of-search-in-2021)              | Blog | Branden Chan (deepset) | Description of the Retriever-Reader pipeline and an introduction to some complementary tasks.                                       |
| [Understanding Semantic Search](https://www.deepset.ai/blog/understanding-semantic-search)                             | Blog | Branden Chan (deepset) | Disambiguates search jargon and explains the differences between various styles of search.                                          |
| [Modern Question Answering Systems Explained](https://www.deepset.ai/blog/modern-question-answering-systems-explained) | Blog | Branden Chan (deepset) | Illustrated deeper dive into the inner workings of the Reader model.                                                                |
| [How to Build an Open-Domain Question Answering System?](https://lilianweng.github.io/posts/2020-10-29-odqa/)          | Blog | Lilian Weng            | Comprehensive look into the inner workings of a Question Answering system. Contains a lot of mathematical notation.                 |

## Word Embeddings / Text Vectorization

https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa
https://www.deepset.ai/blog/what-is-text-vectorization-in-nlp
https://towardsdatascience.com/word-embeddings-for-nlp-5b72991e01d4

## BERT and Transformers
https://jalammar.github.io/illustrated-transformer/
https://towardsdatascience.com/intuitive-explanation-of-bert-bidirectional-transformers-for-nlp-cdc1efc69c1e
https://jalammar.github.io/illustrated-bert/
https://elvissaravia.substack.com/p/learn-about-transformers-a-recipe?s=r
https://medium.com/swlh/bert-139acce0592d




Our blogs???